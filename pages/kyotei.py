import streamlit as st
import requests
from bs4 import BeautifulSoup
import random
from datetime import datetime

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç«¶è‰‡AIäºˆæƒ³", layout="wide")
st.title("ğŸš¤ ç«¶è‰‡AIäºˆæƒ³ - å‡ºèµ°è¡¨ï¼‹äºˆæƒ³çµæœ")

# --- æœ¬æ—¥ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆä¾‹: 20250601ï¼‰---
today = datetime.now().strftime("%Y%m%d")
st.caption(f"ğŸ“… æœ¬æ—¥ï¼š{today}")

# --- URLæ§‹æˆï¼ˆBOATRACEã®å‡ºèµ°è¡¨ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ï¼‰---
BASE_URL = f"https://www.boatrace.jp/owpc/pc/race/raceindex?hd={today}"

# --- ãƒ¬ãƒ¼ã‚¹ä¼šå ´ä¸€è¦§ã‚’å–å¾—ï¼ˆ10ä¼šå ´å‰å¾Œï¼‰---
def get_race_sites():
    try:
        res = requests.get(BASE_URL)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")
        site_tags = soup.select(".contentsFrameInner .race_place")  # ä¼šå ´å
        href_tags = soup.select(".contentsFrameInner .race_place a")  # ãƒªãƒ³ã‚¯
        sites = []
        for name_tag, href_tag in zip(site_tags, href_tags):
            name = name_tag.text.strip()
            href = href_tag.get("href")
            if href:
                full_url = f"https://www.boatrace.jp{href}"
                sites.append((name, full_url))
        return sites
    except Exception as e:
        st.error(f"ä¼šå ´ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼š{e}")
        return []

# --- ç‰¹å®šä¼šå ´ã®ç¬¬1Rå‡ºèµ°è¡¨ã‚’å–å¾— ---
def get_race_table(site_url):
    try:
        race_url = site_url.replace("index", "beforeinfo") + "&rno=1"  # ç¬¬1ãƒ¬ãƒ¼ã‚¹ç”¨
        res = requests.get(race_url)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")
        rows = soup.select("table.is-w495 tbody tr")

        players = []
        for row in rows:
            cols = row.select("td")
            if len(cols) >= 2:
                player_name = cols[1].text.strip()
                if player_name:
                    players.append(player_name)

        race_title_tag = soup.select_one(".headingBlock h2")
        race_title = race_title_tag.text.strip() if race_title_tag else "ãƒ¬ãƒ¼ã‚¹åä¸æ˜"

        return {"ãƒ¬ãƒ¼ã‚¹å": race_title, "é¸æ‰‹": players}
    except Exception as e:
        return {"ã‚¨ãƒ©ãƒ¼": str(e)}

# --- ä»®AIäºˆæƒ³ï¼ˆãƒ©ãƒ³ãƒ€ãƒ 3é€£å˜ï¼‰ ---
def predict_ai(players):
    shuffled = players.copy()
    random.shuffle(shuffled)
    return f"ğŸ¯ äºˆæƒ³ï¼š{shuffled[0]} â†’ {shuffled[1]} â†’ {shuffled[2]}"

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
sites = get_race_sites()

if not sites:
    st.warning("âš ï¸ å‡ºèµ°è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    for name, url in sites:
        st.divider()
        st.subheader(f"ğŸ“ é–‹å‚¬åœ°ï¼š{name}")
        data = get_race_table(url)

        if "ã‚¨ãƒ©ãƒ¼" in data:
            st.error(f"âŒ å‡ºèµ°è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼ï¼š{data['ã‚¨ãƒ©ãƒ¼']}")
            continue

        st.write(f"### ğŸš© {data['ãƒ¬ãƒ¼ã‚¹å']}")
        for i, p in enumerate(data["é¸æ‰‹"], start=1):
            st.write(f"{i}å·è‰‡ï¼š{p}")

        st.write("### ğŸ¤– ä»®AIäºˆæƒ³")
        prediction = predict_ai(data["é¸æ‰‹"])
        st.success(prediction)

st.caption("â€» ç¾åœ¨ã¯ä»®AIã§ã™ã€‚ä»Šå¾Œã€æœ¬ç‰©ã®AIå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBMãªã©ï¼‰ã«é€²åŒ–äºˆå®šã€‚")

